{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatiron School Mod 3 Project\n",
    "\n",
    "## Classifying Steam Games by Price "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\"> Overview: </h2>\n",
    "\n",
    "### What we wanted to find out\n",
    "\n",
    "We were insterested in seeing if computer games can be separated into 4 separate price categories based on the game information and the how the steam community views the game based on user reviews and recommendation. In this experiment, we tried to classify games as:\n",
    "\n",
    "1. Less than $\\$0.99$\n",
    "2. Between $\\$0.99 \\;\\&\\; \\$4.99$\n",
    "3. Between $\\$4.99 \\;\\&\\; \\$9.99$\n",
    "4. More than $\\$9.99$\n",
    "\n",
    "These categories were determined by using the quartiles of the prices from our dataset.\n",
    "\n",
    "<h2 style=\"color:blue\"> The Experiment </h2>\n",
    "\n",
    "### Step 1: Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "from data_getter import *\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, f1_score, mean_squared_error, confusion_matrix, classification_report\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from itertools import cycle\n",
    "from sklearn import svm\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Gather the data\n",
    "\n",
    "To gather the data we scraped information and reviews of 76,000 games from steam.com. Please take a look at data_getter.py for the functions used to gather and clean the data.\n",
    "\n",
    "<h4 style=\"color:green\"> Main Data Gathering Functions</h4>\n",
    "\n",
    "    # retrieve game info for all games\n",
    "    def retrieve_steam_data(start, end):\n",
    "        \"\"\"\n",
    "        takes a start index and end index as integers to slice the games list above\n",
    "        return a list of dictionaries of game info\n",
    "        \"\"\"\n",
    "        data_from_steam_ = []\n",
    "        for num, game in enumerate(games[start: end]):\n",
    "            if game[\"appid\"] >= 10:\n",
    "                data_from_steam_.append(get_game_info(game[\"appid\"]))\n",
    "            # save the data as a json after every thousand iterations\n",
    "            if num % 1000 == 0 and num >0:\n",
    "                t = np.random.choice([1,1.1,1.2,1.3,1.4,1.5])\n",
    "                save_data(data_from_steam_, f\"data_{start}_to_{end}.json\")\n",
    "                print(num, \"Saved!\")\n",
    "                time.sleep(t)\n",
    "            # pause making request to the site after every 100 iterations\n",
    "            elif num % 100 == 0:\n",
    "                t = np.random.choice([1,1.1,1.2,1.3,1.4,1.5])\n",
    "                print(num, t)\n",
    "                time.sleep(t)\n",
    "        return data_from_steam_ \n",
    "\n",
    "    # retrieve user reviews for all games\n",
    "    def retrieve_steam_reviews(id_lst):\n",
    "        \"\"\"\n",
    "        takes a list of game ids\n",
    "        return a list of dictionaries of user reviews of all games in the id_list\n",
    "        \"\"\"\n",
    "        data_from_steam_ = []\n",
    "        for num, appid in enumerate(id_lst):\n",
    "            data_from_steam_.append({appid: get_reviews(appid)})\n",
    "            if num % 1000 == 0 and num >0:\n",
    "                t = np.random.choice([1,1.1,1.2,1.3,1.4,1.5])\n",
    "                save_data(data_from_steam_, f\"upto_{num}_reviews.json\")\n",
    "                print(num, \"Saved!\")\n",
    "                time.sleep(t)\n",
    "            elif num % 100 == 0:\n",
    "                t = np.random.choice([1,1.1,1.2,1.3,1.4,1.5])\n",
    "                print(num, t)\n",
    "                time.sleep(t)\n",
    "        return data_from_steam_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncleaned data of all 76K games\n",
    "raw_data = open_save_data('76K_raw_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, file_to_save_to):\n",
    "        \"\"\"takes in a filename to save to\"\"\"\n",
    "        with open(file_to_save_to, 'w') as outfile:\n",
    "            json.dump(data, outfile)\n",
    "            \n",
    "save_data(all_76K, \"76K_raw_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'open_save_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-db395f7f095f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcleaned_76K\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_save_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ALL_cleaned.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'open_save_data' is not defined"
     ]
    }
   ],
   "source": [
    "cleaned_76K = open_save_data('ALL_cleaned.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
